# Repenser le domaine d'√©valuation pour Tock

> ‚ö†Ô∏è **TOO EARLY** - Ce document contient des r√©flexions exploratoires sur une √©volution future du mod√®le d'√©valuation vers un domaine plus g√©n√©rique et agnostique. Ces concepts ne sont pas encore applicables au design actuel.

## 1. Constat initial

Le design actuel de l'√©valuation dans Tock pr√©sente plusieurs limitations :

- **Approche par cas d'usage** : On est parti de l'√©chantillonnage (use case) et non du domaine m√©tier (√©valuation)
- **Couplage fort** : L'√©valuation est li√©e au sample, au stockage, aux structures Tock (`dialogId`, `actionId`)
- **Extensibilit√© limit√©e** : Ajouter un nouveau canal (feedback utilisateur, LLM) n√©cessiterait une refonte

**Proposition** : D√©finir un domaine d'√©valuation pur, agnostique du syst√®me √©valu√©.

---

## 2. Objectifs du domaine

Concevoir un domaine d'√©valuation permettant :

- **Plusieurs canaux d'√©valuation** : User (feedback live), Admin (QA), Automated (LLM)
- **Plusieurs √©valuateurs** : Humain, IA, Syst√®me
- **Plusieurs types de valeurs** : Emoji, texte, score num√©rique, boolean, √©chelle
- **L'√©valuation de diff√©rents scopes** : Message, conversation, segment, ensemble
- **La r√©cup√©ration des √©l√©ments depuis leur source** : Via une interface abstraite
- **Une s√©paration stricte** entre domaine, UI et infrastructure

---

## 3. Concepts cl√©s - Vue d'ensemble

| Concept | R√¥le |
|---------|------|
| **Evaluation** | Acte d'√©valuer - l'agr√©gat racine |
| **EvaluationScope** | P√©rim√®tre √©valu√© (ce qu'on √©value) |
| **EvaluationChannel** | Contexte d'origine de l'√©valuation |
| **Evaluator** | Qui ou quoi √©value |
| **EvaluationValue** | R√©sultat produit |
| **EvaluationCriterion** | Axe √©valu√© |
| **EvaluationSet** | Ensemble d'√©l√©ments √† √©valuer |
| **EvaluableSource** | Source des √©l√©ments √©valuables |

---

## 4. D√©finition d√©taill√©e des concepts

### 4.1 Evaluation (Agr√©gat racine)

L'√©valuation est l'acte de porter un jugement sur un √©l√©ment. C'est l'agr√©gat racine du domaine.

```kotlin
class Evaluation {
    val id: EvaluationId
    val scope: EvaluationScope       // Ce qu'on √©value
    val channel: EvaluationChannel   // D'o√π vient l'√©valuation
    val evaluator: Evaluator         // Qui √©value
    val values: Set<EvaluationValue> // R√©sultats (‚â• 1)
    val createdAt: Instant
}
```

#### Invariants

1. Une √©valuation porte sur **un seul scope**
2. Une √©valuation provient d'**un seul canal**
3. Une √©valuation est faite par **un seul √©valuateur**
4. Une √©valuation contient **au moins une valeur**
5. Une √©valuation **ne conna√Æt pas** le chatbot, l'UI, ni le stockage

Ces invariants garantissent que l'√©valuation est un concept pur du domaine, sans d√©pendance technique.

---

### 4.2 EvaluationScope

Le scope d√©finit **ce qui est √©valu√©**. C'est le concept central : on √©value toujours quelque chose de pr√©cis.

```kotlin
class EvaluationScope {
    val type: ScopeType
    val reference: ScopeReference
}
```

#### ScopeType

Le type de scope d√©termine la granularit√© de l'√©valuation, en utilisant le vocabulaire Tock :

```kotlin
enum class ScopeType {
    ACTION,          // Une action (message du bot ou de l'utilisateur)
    BOT_ACTION,      // Une action du bot uniquement (r√©ponse)
    DIALOG,          // Un dialogue complet (conversation)
    DIALOG_SEGMENT,  // Une portion de dialogue (√©change Q/R)
    STORY,           // Une story (sc√©nario conversationnel)
    INTENT,          // Une intention NLU
    RAG_QUERY        // Une requ√™te RAG avec sa r√©ponse
}
```

#### ScopeReference

La r√©f√©rence permet de retrouver l'√©l√©ment dans son syst√®me source, sans cr√©er de d√©pendance :

```kotlin
class ScopeReference {
    val externalId: String     // ID dans le syst√®me source
    val sourceSystem: String   // Identifiant du syst√®me source
}
```

#### Description des ScopeTypes

| ScopeType | Description | Exemple de r√©f√©rence |
|-----------|-------------|----------------------|
| `ACTION` | Une action (bot ou user) | `{ externalId: "action_001", sourceSystem: "tock" }` |
| `BOT_ACTION` | Une r√©ponse du bot | `{ externalId: "action_001", sourceSystem: "tock" }` |
| `DIALOG` | Un dialogue complet | `{ externalId: "dialog_abc", sourceSystem: "tock" }` |
| `DIALOG_SEGMENT` | Portion de dialogue | `{ externalId: "dialog_abc:0-3", sourceSystem: "tock" }` |
| `STORY` | Une story/sc√©nario | `{ externalId: "story_greetings", sourceSystem: "tock" }` |
| `INTENT` | Une intention NLU | `{ externalId: "intent_booking", sourceSystem: "tock-nlp" }` |
| `RAG_QUERY` | Requ√™te RAG | `{ externalId: "rag_query_123", sourceSystem: "tock-rag" }` |

#### Extensibilit√©

De nouveaux types de scope peuvent √™tre ajout√©s selon les besoins futurs :

| Scope potentiel | Description |
|-----------------|-------------|
| `SENTENCE` | Une phrase annot√©e NLP |
| `FAQ` | Une entr√©e FAQ |
| `CONFIGURATION` | Un √©l√©ment de configuration bot |

---

### 4.3 EvaluationChannel

Le canal indique le **contexte d'origine** de l'√©valuation : qui a initi√© l'√©valuation et dans quel contexte.

```kotlin
enum class EvaluationChannel {
    USER,      // Feedback live de l'utilisateur final
    ADMIN,     // √âvaluation QA par un humain (back-office)
    AUTOMATED  // √âvaluation automatique (LLM, r√®gles, syst√®me)
}
```

| Canal | Description | Cas d'usage Tock |
|-------|-------------|------------------|
| `USER` | L'utilisateur final donne son avis | Pouce up/down apr√®s une r√©ponse du bot |
| `ADMIN` | Un admin √©value dans le back-office | √âchantillonnage QA pr√©-production |
| `AUTOMATED` | Un syst√®me √©value automatiquement | LLM qui score les r√©ponses RAG |

#### Pourquoi distinguer le canal ?

- **Tra√ßabilit√©** : Savoir d'o√π vient l'√©valuation
- **Pond√©ration** : Une √©valuation ADMIN peut avoir plus de poids qu'un feedback USER
- **Analyse** : Comparer les √©valuations par canal

---

### 4.4 Evaluator

L'√©valuateur indique **qui ou quoi** a produit l'√©valuation.

```kotlin
class Evaluator {
    val id: EvaluatorId
    val type: EvaluatorType
}
```

```kotlin
enum class EvaluatorType {
    HUMAN,   // Personne physique (admin, utilisateur)
    AI,      // Intelligence artificielle (LLM)
    SYSTEM   // R√®gle automatique, script
}
```

| Type | Description | Exemples |
|------|-------------|----------|
| `HUMAN` | Personne physique | Admin Tock, utilisateur final |
| `AI` | Intelligence artificielle | GPT-4, Claude, mod√®le custom |
| `SYSTEM` | R√®gle automatique | D√©tection de pattern, seuil de confiance |

#### Distinction Channel vs Evaluator

- **Channel** = contexte (d'o√π vient l'√©valuation)
- **Evaluator** = acteur (qui a fait l'√©valuation)

Exemples :
- Channel `USER` + Evaluator `HUMAN` = feedback utilisateur classique
- Channel `AUTOMATED` + Evaluator `AI` = scoring LLM
- Channel `AUTOMATED` + Evaluator `SYSTEM` = r√®gle m√©tier automatique
- Channel `ADMIN` + Evaluator `HUMAN` = QA manuel

---

### 4.5 EvaluationValue et EvaluationCriterion

Une √©valuation produit une ou plusieurs **valeurs** sur un ou plusieurs **crit√®res**.

#### EvaluationCriterion

Le crit√®re d√©finit **l'axe √©valu√©** :

```kotlin
class EvaluationCriterion {
    val name: String  // Ex: "quality", "relevance", "helpfulness", "accuracy"
}
```

Exemples de crit√®res :
- `quality` : La r√©ponse est-elle de bonne qualit√© ?
- `relevance` : La r√©ponse est-elle pertinente par rapport √† la question ?
- `helpfulness` : La r√©ponse aide-t-elle l'utilisateur ?
- `accuracy` : La r√©ponse est-elle exacte ?
- `reason` : Quelle est la raison d'un KO ?

#### EvaluationValue

La valeur associe un crit√®re √† un r√©sultat :

```kotlin
class EvaluationValue {
    val criterion: EvaluationCriterion
    val value: Value
}
```

#### Value (polymorphe)

L'interface `Value` permet diff√©rents types de r√©sultats :

```kotlin
interface Value

class BooleanValue(val value: Boolean) : Value           // OK/KO, Oui/Non
class NumericValue(val value: Double) : Value            // Score 0.0-1.0
class TextValue(val value: String) : Value               // Commentaire, raison
class EmojiValue(val value: String) : Value              // üëç üëé üòê
class ScaleValue(val value: Int, val max: Int) : Value   // 3/5, 4/10
```

#### Adaptation du design actuel

| Design actuel | Nouveau design |
|---------------|----------------|
| `evaluation: OK` | `{ criterion: "quality", value: BooleanValue(true) }` |
| `evaluation: KO` | `{ criterion: "quality", value: BooleanValue(false) }` |
| `reason: HALLUCINATION` | `{ criterion: "reason", value: TextValue("HALLUCINATION") }` |

#### √âvaluation multi-crit√®res

Une m√™me √©valuation peut contenir plusieurs valeurs :

```json
{
  "values": [
    { "criterion": { "name": "quality" }, "value": { "type": "boolean", "value": true } },
    { "criterion": { "name": "relevance" }, "value": { "type": "numeric", "value": 0.85 } },
    { "criterion": { "name": "comment" }, "value": { "type": "text", "value": "Bonne r√©ponse" } }
  ]
}
```

---

### 4.6 EvaluationSet

Un ensemble d'√©l√©ments √† √©valuer, regroup√©s pour un objectif commun.

```kotlin
class EvaluationSet {
    val id: EvaluationSetId
    val name: String
    val purpose: String
    val items: Set<EvaluableReference>
    val createdAt: Instant
}
```

```kotlin
class EvaluableReference {
    val type: ScopeType           // BOT_ACTION, DIALOG, RAG_QUERY, etc.
    val reference: ScopeReference
}
```

#### Adaptation Tock

| Design actuel | Nouveau design |
|---------------|----------------|
| `EvaluationSample` | `EvaluationSet` de type QA_SAMPLING |
| `botActionRefs[]` | `items: Set<EvaluableReference>` avec `type = BOT_ACTION` |

#### Extension : type et cycle de vie

Pour supporter diff√©rents cas d'usage, on peut typer les sets et leur associer un cycle de vie :

```kotlin
class EvaluationSet {
    // ... champs de base
    val setType: EvaluationSetType  // QA_SAMPLING, LLM_BATCH, SPEC_VALIDATION
    val status: Status
}
```

Cycle de vie g√©r√© via un endpoint g√©n√©rique `change-status` au lieu d'actions fig√©es `/validate`, `/cancel`.

Exemples de cycles de vie par type :

| Type | Cycle de vie |
|------|--------------|
| `QA_SAMPLING` | `IN_PROGRESS ‚Üí VALIDATED \| CANCELLED` |
| `LLM_BATCH` | `PENDING ‚Üí PROCESSING ‚Üí COMPLETED \| FAILED` |
| `SPEC_VALIDATION` | `DRAFT ‚Üí IN_PROGRESS ‚Üí PASSED \| FAILED` |

---

### 4.7 EvaluableSource

Interface pour **r√©cup√©rer les √©l√©ments √©valuables** depuis leur syst√®me source.

```kotlin
interface EvaluableSource {
    fun id(): SourceId
    fun type(): SourceType
    fun fetch(query: EvaluableQuery): List<EvaluableReference>
}
```

```kotlin
enum class SourceType {
    CHAT_SYSTEM,        // Syst√®me de chat (Tock dialogs)
    ADMIN_DATASET,      // Dataset admin (specs de test)
    MONITORING_PIPELINE // Pipeline de monitoring
}
```

```kotlin
class EvaluableQuery {
    val scopeType: ScopeType   // BOT_ACTION, DIALOG, RAG_QUERY, etc.
    val timeRange: TimeRange
    val filters: Map<String, String>
    val limit: Int
}
```

#### Impl√©mentations Tock

| Source | Description | ScopeTypes support√©s |
|--------|-------------|----------------------|
| `TockDialogSource` | R√©cup√®re depuis la collection dialogs | ACTION, BOT_ACTION, DIALOG, DIALOG_SEGMENT |
| `TockStorySource` | R√©cup√®re depuis les stories | STORY |
| `TockNlpSource` | R√©cup√®re depuis le mod√®le NLP | INTENT |
| `TockRagSource` | R√©cup√®re depuis le syst√®me RAG | RAG_QUERY |

---

## 5. S√©parations fondamentales

Le domaine d'√©valuation doit respecter ces principes de s√©paration :

| Principe | Description |
|----------|-------------|
| L'√©valuation **ne conna√Æt pas l'UI** | Pas de d√©pendance aux composants d'affichage |
| L'√©valuation **ne conna√Æt pas le stockage** | Pas de d√©pendance √† MongoDB, etc. |
| L'√©valuation **ne conna√Æt pas le chatbot** | Pas de d√©pendance aux structures Tock |
| Tout passe par des **r√©f√©rences externes** | `ScopeReference` au lieu de `dialogId` |

#### B√©n√©fices de ces s√©parations

1. **Testabilit√©** : Le domaine peut √™tre test√© en isolation
2. **√âvolutivit√©** : Nouveaux canaux, sources, valeurs sans refonte
3. **R√©utilisabilit√©** : Le domaine pourrait √™tre utilis√© hors Tock
4. **Maintenabilit√©** : Changements localis√©s, pas d'effets de bord

---

## 6. Mental Model

Le flux de donn√©es suit ce chemin :

```
Chat System ‚Üí EvaluableSource ‚Üí EvaluableReference ‚Üí EvaluationScope ‚Üí Evaluation
```

```mermaid
flowchart LR
    subgraph external [Syst√®mes Tock]
        Dialogs[Dialogs & Actions]
        Stories[Stories]
        NLP[NLP / Intents]
        RAG[RAG Queries]
    end
    
    subgraph domain [Domaine Evaluation]
        Source[EvaluableSource]
        Ref[EvaluableReference]
        Scope[EvaluationScope]
        Eval[Evaluation]
        Values[EvaluationValues]
    end
    
    Dialogs --> Source
    Stories --> Source
    NLP --> Source
    RAG --> Source
    Source --> Ref
    Ref --> Scope
    Scope --> Eval
    Eval --> Values
```

---

## 7. Impact sur le design actuel

| Aspect | Design actuel | Nouveau design |
|--------|---------------|----------------|
| **√âvaluation** | Sous-ressource de Sample | Ressource autonome |
| **URL** | `/samples/:id/evaluations` | `/evaluations` (top-level) |
| **Scope** | `dialogId` + `actionId` | `EvaluationScope { type: BOT_ACTION, reference }` |
| **Types de scope** | Implicite (action bot) | Explicite : `BOT_ACTION`, `DIALOG`, `RAG_QUERY`, etc. |
| **Valeur** | `OK/KO` + `reason` | `EvaluationValue[]` polymorphe |
| **√âvaluateur** | `evaluatedBy: String` | `Evaluator { id, type }` |
| **Sample** | Sp√©cifique Tock | `EvaluationSet` g√©n√©rique |
| **Source** | Hardcod√© dialogs | `EvaluableSource` interface |
| **Cycle de vie** | `/validate`, `/cancel` | `/change-status` g√©n√©rique |

---

## 8. Redesign des APIs

### 8.1 √âvaluation comme ressource autonome

```http
POST   /evaluations
GET    /evaluations
GET    /evaluations/:id
PATCH  /evaluations/:id
DELETE /evaluations/:id
GET    /evaluations?scope.reference.externalId=xxx
```

#### Exemple : Cr√©er une √©valuation (QA Admin)

```http
POST /evaluations
```

```json
{
  "scope": {
    "type": "BOT_ACTION",
    "reference": {
      "externalId": "action_001",
      "sourceSystem": "tock"
    }
  },
  "channel": "ADMIN",
  "evaluator": {
    "id": "user-123",
    "type": "HUMAN"
  },
  "values": [
    {
      "criterion": { "name": "quality" },
      "value": { "type": "boolean", "value": true }
    }
  ]
}
```

#### Exemple : √âvaluation LLM automatique sur un dialogue

```http
POST /evaluations
```

```json
{
  "scope": {
    "type": "DIALOG",
    "reference": {
      "externalId": "dialog_abc",
      "sourceSystem": "tock"
    }
  },
  "channel": "AUTOMATED",
  "evaluator": {
    "id": "gpt-4",
    "type": "AI"
  },
  "values": [
    {
      "criterion": { "name": "coherence" },
      "value": { "type": "numeric", "value": 0.85 }
    },
    {
      "criterion": { "name": "helpfulness" },
      "value": { "type": "numeric", "value": 0.92 }
    }
  ]
}
```

#### Exemple : Feedback utilisateur sur une r√©ponse

```http
POST /evaluations
```

```json
{
  "scope": {
    "type": "BOT_ACTION",
    "reference": {
      "externalId": "action_042",
      "sourceSystem": "tock"
    }
  },
  "channel": "USER",
  "evaluator": {
    "id": "anonymous-session-xyz",
    "type": "HUMAN"
  },
  "values": [
    {
      "criterion": { "name": "helpful" },
      "value": { "type": "emoji", "value": "üëç" }
    }
  ]
}
```

#### Exemple : √âvaluation d'une requ√™te RAG

```http
POST /evaluations
```

```json
{
  "scope": {
    "type": "RAG_QUERY",
    "reference": {
      "externalId": "rag_query_789",
      "sourceSystem": "tock-rag"
    }
  },
  "channel": "AUTOMATED",
  "evaluator": {
    "id": "ragas-evaluator",
    "type": "AI"
  },
  "values": [
    {
      "criterion": { "name": "faithfulness" },
      "value": { "type": "numeric", "value": 0.91 }
    },
    {
      "criterion": { "name": "answer_relevancy" },
      "value": { "type": "numeric", "value": 0.88 }
    }
  ]
}
```

### 8.2 EvaluationSet avec cycle de vie g√©n√©rique

```http
POST   /evaluation-sets
GET    /evaluation-sets
GET    /evaluation-sets/:id
POST   /evaluation-sets/:id/change-status
GET    /evaluation-sets/:id/content
```

#### Exemple : Cr√©er un set QA sur des r√©ponses bot

```http
POST /evaluation-sets
```

```json
{
  "name": "QA Q1 2026",
  "purpose": "Validation avant mise en prod",
  "setType": "QA_SAMPLING",
  "source": {
    "type": "TOCK_DIALOGS",
    "query": {
      "scopeType": "BOT_ACTION",
      "timeRange": {
        "from": "2026-01-01T00:00:00Z",
        "to": "2026-01-14T23:59:59Z"
      },
      "filters": {
        "applicationName": "my-bot",
        "namespace": "my-ns"
      },
      "limit": 50
    }
  }
}
```

#### Exemple : Cr√©er un set d'√©valuation RAG

```http
POST /evaluation-sets
```

```json
{
  "name": "RAG Audit Janvier",
  "purpose": "√âvaluation qualit√© des r√©ponses RAG",
  "setType": "LLM_BATCH",
  "source": {
    "type": "TOCK_RAG",
    "query": {
      "scopeType": "RAG_QUERY",
      "timeRange": {
        "from": "2026-01-01T00:00:00Z",
        "to": "2026-01-31T23:59:59Z"
      },
      "limit": 100
    }
  }
}
```

#### Exemple : Changer le statut

```http
POST /evaluation-sets/:id/change-status
```

```json
{
  "targetStatus": "VALIDATED",
  "comment": "√âvaluation compl√®te, bot valid√©"
}
```

Response 200 :
```json
{
  "_id": "set_123",
  "status": "VALIDATED",
  "statusHistory": [
    {
      "from": "IN_PROGRESS",
      "to": "VALIDATED",
      "at": "2026-01-15T10:00:00Z",
      "by": "user-123",
      "comment": "√âvaluation compl√®te, bot valid√©"
    }
  ]
}
```

Response 422 (transition invalide) :
```json
{
  "error": "Invalid status transition",
  "currentStatus": "VALIDATED",
  "targetStatus": "IN_PROGRESS",
  "allowedTransitions": []
}
```

---

## 9. Int√©gration Front

### 9.1 Principes

- Le front travaille avec des **ressources REST classiques**
- L'√©valuation **n'est plus une sous-ressource** du set
- Le contenu des scopes est r√©cup√©r√© via `/content`
- Le cycle de vie est pilot√© par `change-status`

### 9.2 Flow d'√©valuation QA

```mermaid
sequenceDiagram
    participant Front
    participant API
    participant EvalStore as Evaluations
    participant SetStore as EvaluationSets
    participant Source as EvaluableSource

    Front->>API: POST /evaluation-sets
    API->>Source: fetch(query)
    Source-->>API: items[]
    API->>SetStore: create(set + items)
    API-->>Front: set created

    Front->>API: GET /evaluation-sets/:id
    API-->>Front: set + items + stats

    Front->>API: GET /evaluation-sets/:id/content
    API->>Source: getContent(items)
    Source-->>API: dialogs/messages
    API-->>Front: content

    Front->>API: GET /evaluations?evaluationSetId=xxx
    API->>EvalStore: find(setId)
    API-->>Front: evaluations[]

    Note over Front: Fusionne items + content + evaluations

    Front->>API: POST /evaluations
    API->>EvalStore: create(evaluation)
    API-->>Front: evaluation created
```

### 9.3 Avantages pour le front

1. **Ressources standard** : CRUD classique sur `/evaluations`
2. **Pas de logique sp√©ciale** : Une √©valuation se cr√©e de la m√™me fa√ßon quel que soit le contexte
3. **R√©utilisable** : Le m√™me composant peut servir pour QA, feedback user, etc.

---

## 10. √âvolutions potentielles pour Tock

Ce mod√®le g√©n√©rique ouvre la porte √† de nombreuses √©volutions :

| √âvolution | Canal | Scope | Evaluator | Valeur |
|-----------|-------|-------|-----------|--------|
| **Feedback utilisateur live** | USER | BOT_ACTION | HUMAN | Emoji, Boolean |
| **QA √©chantillonnage** | ADMIN | BOT_ACTION | HUMAN | Boolean + Reason |
| **√âvaluation LLM par action** | AUTOMATED | BOT_ACTION | AI | Numeric scores |
| **√âvaluation LLM par dialogue** | AUTOMATED | DIALOG | AI | Numeric scores |
| **Audit RAG (RAGAS)** | AUTOMATED | RAG_QUERY | AI | Faithfulness, Relevancy |
| **Validation de story** | ADMIN | STORY | HUMAN | Boolean |
| **Benchmarking NLU** | AUTOMATED | INTENT | SYSTEM | Precision, Recall |
| **Analyse segment** | AUTOMATED | DIALOG_SEGMENT | AI | Multi-crit√®res |

---

## 11. Analyse critique

### Points forts

| Aspect | B√©n√©fice |
|--------|----------|
| **Domaine pur** | Testable, maintenable, √©volutif |
| **D√©couplage** | Pas de d√©pendance √† Tock, MongoDB, UI |
| **Extensibilit√©** | Nouveaux canaux, scopes, valeurs sans refonte |
| **Multi-canal natif** | USER, ADMIN, AUTOMATED support√©s d√®s le d√©part |
| **Coh√©rence** | M√™me mod√®le pour tous les cas d'usage |

### Points √† challenger

| Aspect | Risque | Mitigation |
|--------|--------|------------|
| **Complexit√© initiale** | Over-engineering pour un besoin simple ? | Impl√©menter progressivement |
| **Co√ªt de l'abstraction** | Performance, indirection | Optimiser les cas critiques |
| **Migration** | Existant √† faire √©voluer | Migration progressive, r√©trocompatibilit√© |
| **Courbe d'apprentissage** | Nouveaux concepts √† assimiler | Documentation, exemples |

---

## 12. Questions pour l'√©quipe

1. **Niveau d'abstraction** : Ce mod√®le g√©n√©rique est-il justifi√© pour les besoins actuels et futurs de Tock ?

2. **Priorit√©s** : Quels canaux prioriser apr√®s ADMIN ?
   - Feedback utilisateur live ?
   - √âvaluation LLM automatique ?

3. **Migration** : Comment g√©rer la transition ?
   - Big bang vs migration progressive ?
   - R√©trocompatibilit√© API ?

4. **Existant** : Le feedback utilisateur existe-t-il d√©j√† dans Tock sous une autre forme ?

5. **Crit√®res** : Quels crit√®res d'√©valuation sont pertinents pour Tock ?
   - Quality, Relevance, Helpfulness ?
   - Crit√®res sp√©cifiques RAG ?

---

## 13. Conclusion

Le mod√®le propos√© offre une base solide pour :

- **Court terme** : Impl√©menter l'√©chantillonnage QA avec une architecture propre
- **Moyen terme** : Ajouter le feedback utilisateur et l'√©valuation LLM
- **Long terme** : Construire un syst√®me d'√©valuation complet et √©volutif

La cl√© est de **s√©parer le domaine d'√©valuation** (concepts purs) des **cas d'usage** (√©chantillonnage, feedback, LLM) et de l'**infrastructure** (Tock, MongoDB).

